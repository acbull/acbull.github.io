<!DOCTYPE html>
<html lang="en-us">
   <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />
      <meta http-equiv="X-UA-Compatible" content="IE=edge" />
      <meta name="theme" content="hugo-academic" />
      <meta name="generator" content="Hugo 0.19" />
      <meta name="author" content="Ziniu Hu" />
      <meta name="description" content="Bachelor of Computer Science" />
      <link rel="stylesheet" href="/css/highlight.min.css" />
      <link rel="stylesheet" href="/css/bootstrap.min.css" />
      <link rel="stylesheet" href="/css/font-awesome.min.css" />
      <link rel="stylesheet" href="/css/academicons.min.css" />
      <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono" />
      <link rel="stylesheet" href="/css/hugo-academic.css" />
      <link rel="alternate" href="https://tpbull.github.io/index.xml" type="application/rss+xml"
         title="Ziniu Hu's Website" />
      <link rel="feed" href="https://tpbull.github.io/index.xml" type="application/rss+xml" title="Ziniu Hu's Website" />
      <link rel="icon" type="image/png" href="/img/icon.png" />
      <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png" />
      <link rel="canonical" href="https://tpbull.github.io/" />
      <title>Ziniu Hu's Website</title>
      <script>var _hmt = _hmt || []; (function () {
         var hm = document.createElement("script");
         hm.src = "https://hm.baidu.com/hm.js?c83bf8b7e066e7c41af36a85a5651bf2";
         var s = document.getElementsByTagName("script")[0];
         s.parentNode.insertBefore(hm, s);
         })();
      </script>
   </head>
   <body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">
      <nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
         <div class="container">
            <div class="navbar-header">
               <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                  data-target=".navbar-collapse" aria-expanded="false">
               <span class="sr-only">Toggle navigation</span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               </button>
               <a class="navbar-brand" href="/">Ziniu Hu's Website</a>
            </div>
            <div class="collapse navbar-collapse">
               <ul class="nav navbar-nav navbar-right">
                  <li class="nav-item">
                     <a href="/#about" data-target="#about">
                     <span>About</span></a>
                  </li>
                  <li class="nav-item">
                     <a href="/#publications_selected" data-target="#publications_selected">
                     <span>Publications</span></a>
                  </li>
                  <li class="nav-item">
                     <a href="/#service" data-target="#service">
                     <span>Service</span></a>
                  </li>
               </ul>
            </div>
         </div>
      </nav>
      <span id="homepage" style="display: none"></span>
      <section id="about" class="home-section">
         <div class="container">
            <div class="row" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
               <div class="col-xs-12 col-md-4">
                  <div id="profile">
                     <div class="portrait" itemprop="image" style="background-image: url('/img/photo.jpg');"></div>
                     <div class="portrait-title">
                        <h2 itemprop="name">Ziniu Hu</h2>
                     </div>
                     <p>
                        <a href="https://twitter.com/acbuller"><i class="fa fa-twitter fa-2x"></i></a> &nbsp &nbsp
                        <a href="https://www.linkedin.com/in/ziniu-hu-1bb92813a/"><i
                           class="fa fa-linkedin fa-2x"></i></a>&nbsp &nbsp
                        <a href="https://scholar.google.com/citations?user=x6ct1CsAAAAJ&hl=en"><i
                           class="ai ai-google-scholar ai-2x"></i></a>&nbsp &nbsp
                        <a href="https://github.com/acbull"><i class="fa fa-github fa-2x"></i></a>
                     <center><img alt="GitHub Repo stars" src="https://img.shields.io/badge/total_stars-5.3k-blue?logo=github&style=for-the-badge"></center>
                     </p>
                  </div>
               </div>
               <div class="col-xs-13 col-md-8" itemprop="description">
                  <h1 id="biography">About</h1>
                  <p>I am now working at <a href="https://x.ai/">xAI</a>, reinforcing Large Language Models (e.g. <a href="https://x.ai/news/grok-code-fast-1">Grok Code Fast 1</a>, <a href="https://x.com/xai/status/1913308977477353582">Grok 3-mini Reasoning API</a>, <a href="https://x.ai/blog/grok-3">Grok 3</a> and <a href="https://x.ai/blog/grok-1212">Grok 2</a>) to solve problems.</p>
                  <p>I finished Postdoc at <a href="https://www.cms.caltech.edu/">Caltech CMS</a> hosted by Prof. <a href="http://www.yisongyue.com/">Yisong Yue</a>, during which I was also a visiting researcher at Google DeepMind. I received CS PhD degree at UCLA, where I had the fortune to be advised by Prof. <a href="http://web.cs.ucla.edu/~yzsun/">Yizhou
                     Sun</a> and Prof. <a href="http://web.cs.ucla.edu/~kwchang/">Kai-Wei
                     Chang</a>. I received my CS bachelor degree at Peking University, advised by
                     Prof. <a href="http://www.liuxuanzhe.com/">Xuanzhe Liu</a>. My research is generously supported by <a href="https://www.sciencehub.ucla.edu/2021-amazon-fellows/">Amazon PhD
                     Fellowship</a> and <a href="https://www.laitimes.com/en/article/1cw4x_1eed6.html">Baidu Scholarship</a>. My PhD thesis on <a href="https://drive.google.com/file/d/1klr8BfkzvZaN_iKMLKCPyY3OKi4-E3MK/view?usp=drive_link">Neural-Symbolic AI</a> won the <a href="https://kdd2024.kdd.org/awards/"> <b>ACM KDD 2024 Dissertation Award - Runner Up</b> </a>.
                  </p>
               </div>
               <div class="col-md-12">
                  <div class="col-sm-4">
                     <h3>Education</h3>
                     <ul class="ul-edu fa-ul">
                        <li>
                           <i class="fa-li fa fa-graduation-cap"></i>
                           <div class="description">
                              <p class="course">Ph.D. of Computer Science
                                 <br />Sept. 2018 -- May 2023
                              </p>
                              <p class="institution">University of Calofornia, Los Angeles</p>
                              <p class="institution"> <b>Thesis: <a href="https://drive.google.com/file/d/1klr8BfkzvZaN_iKMLKCPyY3OKi4-E3MK/view?usp=drive_link">Make Knowledge Computable: Towards Differentiable Neural-Symbolic AI</a></b>
                           </div>
                        </li>
                        <li>
                           <i class="fa-li fa fa-graduation-cap"></i>
                           <div class="description">
                              <p class="course">B.Sc. of Computer Science
                                 <br />Sept. 2014 -- Jun. 2018
                              </p>
                              <p class="institution">Peking University</p>
                           </div>
                        </li>
                     </ul>
                  </div>
                  <div class="col-sm-8">
                     <h3>Academic Awards</h3>
                     <ul class="ul-interests">
                        <li><a href="https://kdd2024.kdd.org/awards/"> <b>ACM SIGKDD 2024 Dissertation Award - Runner Up</b> </a></li>
                        <li><a href="https://dlde-2023.github.io/"> <b>Best Paper Award, NeurIPS 2023 Workshop (DL + Differential Equation)</b> </a></li>
                        <li><a href="https://socalnlp.github.io/symp22/index.html"> <b>Best Paper Award, SoCal NLP Symposium 2022</b> </a></li>
                        <li><a href="https://deep-learning-graphs.bitbucket.io/dlg-kdd20/"><b>Best Student Paper Award, KDD 2020 Workshop (DL on Graphs)</b></a></li>
                        <li><a href="https://archives.iw3c2.org/www2019/winners/"><b>Best Full Paper Award, WWW 2019 </b></a></li>
                     </ul>
                     <h3>Services</h3>
                     <ul class="ul-interests">
                        <li><a href="https://sites.cs.ucsb.edu/~xyan/KDD23-ResearchTrack-Banquet-Talk.pdf"> <b>Research Track Workflow Co-Chair: SIGKDD 2023</b> </a></li>
                        <li> <b>Area Chair</b> of <b>ICLR NeurIPS, ACL</b> 2025, <b>ICLR</b> 2026</li>
                        <li><a href="https://neurips.cc/Conferences/2022/ProgramCommittee"> <b>NeurIPS 2022 Top Reviewer Award</b></a> </li>
                        <li>Workshop Co-Organizer of <a href="https://sites.google.com/corp/view/tavi-cvpr24/">Tool-VLM @ CVPR'24</a> and <a href="https://www.aminer.cn/ssl_www2021">SSL @ WWW'21</a> </li>
                     </ul>
                     <h3>Fellowships</h3>
                     <ul class="ul-interests">
                        <li><a href="https://www.cms.caltech.edu/academics/honors">Computing, Data, and Society Fellow at Caltech, 2023</a></li>
                        <li><a href="https://www.laitimes.com/en/article/1cw4x_1eed6.html"><b>Baidu Scholarship (10 PhD students worldwide), 2021</b> </a> </li>
                        <li><a href="https://www.sciencehub.ucla.edu/2021-amazon-fellows/">Amazon PhD Fellowship, 2021-2022</a></li>
                        <li><a href="https://www.sensetime.com/en/technology-personnel">SenseTime Scholarship, 2018</a></li>
                        <li><a href="https://www.sensetime.com/en/technology-personnel">May 4th Scholarship of Peking University, 2016</a></li>
                     </ul>
                  </div>
               </div>
               <!--                <div class="col-md-12">
                  <div class="col-sm-12">
                     <h3>Intern Experience</h3>
                     <ul class="ul-interests">
                        <li>
                           <p class="institution">Jun 2022 -- Now, Google Research<br />
                              <small>Working with
                              <a href="https://www.alirezafathi.org/">Alireza Fathi</a>, <a href="http://www.cs.toronto.edu/~dross/">David Ross</a>, <a href="https://chensun.me/">Chen Sun</a> and <a href="https://thoth.inrialpes.fr/~schmid/">Cordelia Schmid</a> on Knowledge-Augmented Visual-Language Model.</small>
                           </p>
                        </li>
                        <li>
                           <p class="institution">Jun 2021 -- Dec 2021, Google Brain<br />
                              <small>Worked with
                              <a href="https://research.google/people/105547/">Zhe Zhao</a>, <a
                                 href="https://research.google/people/105550/">Xinyang Yi</a> and <a
                                 href="https://www.linkedin.com/in/tianshengyao/">Tiansheng Yao</a> on Improving Multi-Task Generalization.</small>
                           </p>
                        </li>
                        <li>
                           <p class="institution">Jun 2019 -- Sep 2019, Microsoft Research Redmond
                              <br />
                              <small>Worked with
                              <a href="https://ericdongyx.github.io/">Yuxiao Dong</a> on billion-scale
                              heterogeneous graph transformer & pre-train.</small>
                           </p>
                        </li>
                        <li>
                           <p class="institution">Feb 2018 -- Aug 2018, ByteDance AI Lab
                              <br />
                              <small>Worked with
                              <a href="http://hangli-hl.com/index.html">Hang Li</a> on pairwise unbiased
                              learning-to-rank.</small>
                           </p>
                        </li>
                        <li>
                           <p class="institution">Feb 2017 -- Aug 2017, Microsoft Research Asia
                              <br />
                              <small>Worked with
                              <a href="https://sites.google.com/view/jiangbian">Jiang Bian</a> on
                              news-oriented stock trend prediction.</small>
                           </p>
                        </li>
                     </ul>
                  </div>
                  </div> -->
            </div>
         </div>
      </section>
      <section id="publications_selected" class="home-section">
         <div class="container">
            <!--             <div class="row">
               <div class="col-xs-12 col-md-6 section-heading">
                  <h1>Preprints</h1>
               </div>
               <div class="col-xs-12">
                  <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:#D8D8D8;height:3px" />
                  
               </div>
               </div> -->
            <div class="row">
               <div class="col-xs-12 col-md-6 section-heading">
                  <h1>Selected Publications</h1>
               </div>
               <div class="col-xs-12">
                  <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:#D8D8D8;height:3px" />
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">TreeRL: LLM Reinforcement Learning with On-Policy Tree Search </h5>
                           <div class="pub-authors" itemprop="author">Zhenyu Hou*, <u><b>Ziniu Hu*</b></u>, Yujiang Li*, Rui Lu*, Jie Tang, Yuxiao Dong</u>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2506.11902">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/THUDM/TreeRL">CODE</a>
                           </div>
                           <div class="pub-publication"> Conference of the Association for Computational Linguistics (ACL 2025)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/treerl.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose TreeRL, a reinforcement learning framework that directly incorporates on-policy tree search for LLM RL training, as well as a cost-effective tree search approach that strategically branch from high-entropy tokens.</div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search </h5>
                           <div class="pub-authors" itemprop="author">Jonathan Light, Min Cai, Weiqin Chen, Guanzhi Wang, Xiusi Chen, Wei Cheng, Yisong Yue, <u><b>Ziniu Hu</b></u>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2408.10635">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/jonathanmli/Avalon-LLM/tree/main/strategist">CODE</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://llm-strategist.github.io/">DEMO</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/jonathanmli/Avalon-LLM?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> International Conference on Learning Representations (ICLR 2025)
                           </div>
                           <div class="pub-publication"> Covered by <a href="https://docs.google.com/presentation/d/1GmZmoWOa2O92BPrncRcTKa15xvQGhq7g4I4hJSNlC0M/edit#slide=id.g2d35a16f27e_0_24"> State of AI Report 2024 </a>, published by <a href="https://www.stateof.ai/">Air Street Capital</a>.
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/strategy.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose Strategist, a method allowing LLMs to learn new skills for multi-agent games. With bi-level tree search approach, combining high-level strategic learning with low-level simulated self-play for feedback. It outperformed RL and other LLM-based approaches on Game of Pure Strategy and The Resistance: Avalon at action planning and dialogue generation.</div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Multi-Token Joint Speculative Decoding for Accelerating Large Language Model Inference </h5>
                           <div class="pub-authors" itemprop="author">Zongyue Qin, <u><b>Ziniu Hu</b></u>, Zifan He, Neha Prakriya, Jason Cong, Yizhou Sun
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2407.09722">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/ZongyueQin/MTAD">CODE</a>
                           </div>
                           <div class="pub-publication"> International Conference on Learning Representations (ICLR 2025)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/speculative.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose a novel decoding that improves perplexity and downstream performance with 1.4 times faster and 1.5 times less energy cost compared to speculative decoding by considering joint probability of multiple tokens.</div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search </h5>
                           <div class="pub-authors" itemprop="author">Zongyu Lin, Yao Tang, Xingcheng Yao, Da Yin, Ziniu Hu, Yizhou Sun, Kai-Wei Chang
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2502.02584">PDF</a>
                           </div>
                           <div class="pub-publication"> International Conference on Machine Learning (ICML 2025)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/qlass.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text"> QLASS (Q-guided Language Agent Stepwise Search), is a framework that supercharges language agents at inference time. We build a process reward model to guide open language agents on complex interactive tasks by estimating the Q-value of each step without any human annotation.</div>
                        </div>
                     </div>
                  </div>
<!--                   <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Scattered Forest Search: Smarter Code Space Exploration with LLMs </h5>
                           <div class="pub-authors" itemprop="author">Jonathan Light, Yue Wu, Yiyou Sun, Wenchao Yu, Yanchi Liu, Xujiang Zhao, <u><b>Ziniu Hu</b></u>, Haifeng Chen, Wei Cheng
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2411.05010">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/codespace-optimization/sfs">CODE</a>
                           </div>
                           <div class="pub-publication"> International Conference on Learning Representations (ICLR 2025)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/forests.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propos SCATTERED FOREST SEARCH that improves code generation by enhancing solution diversity, achieving significant performance gains (e.g., 8.6% on HumanEval+) and reducing the iterations needed to find correct solutions by half compared to existing methods.</div>
                        </div>
                     </div>
                  </div> -->
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search </h5>
                           <div class="pub-authors" itemprop="author">
                              Dan Zhang, Sining Zhoubian, <u><b>Ziniu Hu</b></u>, Yisong Yue, Yuxiao Dong, Jie Tang
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2406.03816">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/THUDM/ReST-MCTS">CODE</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/THUDM/ReST-MCTS?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2024) </a>
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/rest.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">In this paper, we develop a reinforced self-training approach, called ReST-MCTS*, based on integrating process reward guidance with tree search MCTS* for collecting higher-quality reasoning traces as well as per-step value to train policy and reward models. ReST-MCTS* circumvents the per-step manual annotation typically used to train process rewards by tree-search-based reinforcement learning: Given oracle final correct answers, ReST-MCTS* is able to infer the correct process rewards by estimating the probability this step can help lead to the correct answer. These inferred rewards serve dual purposes: they act as value targets for further refining the process reward model and also facilitate the selection of high-quality traces for policy model self-training. </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">SciInstruct: a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models </h5>
                           <div class="pub-authors" itemprop="author">
                              Dan Zhang, <u><b>Ziniu Hu</b></u>, Sining Zhoubian, Zhengxiao Du, Kaiyu Yang, Zihan Wang, Yisong Yue, Yuxiao Dong, Jie Tang
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2401.07950">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/THUDM/SciGLM">CODE</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/THUDM/SciGLM?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2024, Dataset Track)</a>
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/sciglm-1.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We use LLM to self-curated SciInstruct, a diverse and high-quality dataset of college-level mathematics, physics, chemistry, and formal proofs. Using SciInstruct to finetune the ChatGLM family of LLMs, we introduce SciGLM, a suite of scientific language models for college-level mathematical/scientific reasoning. </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Physics-Informed Regularization for Domain-Agnostic Dynamical System Modeling</h5>
                           <div class="pub-authors" itemprop="author">
                              Zijie Huang*, Wanjia Zhao*, Jingdong Gao, <u><b>Ziniu Hu</b></u>, Xiao Luo, Yadi Cao, Yuanzhou Chen, Yizhou Sun, Wei Wang
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2310.06427.pdf">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/mxuan0/TANGO">CODE</a>
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2024), <a href="https://dlde-2023.github.io/"> Best Paper Award at NeurIPS 2023, Deep Learning and Differential Equations (DLDE) workshop </a>
                           </div>
                           <div class="col-md-3" style="top:20px">
                              <img src="/img/headers/tango.jpg" class="pub-banner" itemprop="image" />
                           </div>
                           <div class="col-md-8" style="top:10px">
                              <div class="pub-abstract" itemprop="text">We propose a physical-law-guided regularization term corresponding to a soft constraint of time-reversal symmetry. The term is applied to GraphODE models for multi-agent dynamical systems and demonstrated as superior to several baselines on a variety of benchmarks, including the challenging pendulum problem.    </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Enhancing Large Vision Language Models with Self-Training on Image Comprehension </h5>
                           <div class="pub-authors" itemprop="author">Yihe Deng, Pan Lu, Fan Yin, <u><b>Ziniu Hu</b></u>, Sheng Shen, James Zou, Kai-Wei Chang, Wei Wang
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2405.19716">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/yihedeng9/STIC">CODE</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://stic-lvlm.github.io/">WEBSITE</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/yihedeng9/STIC?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2024)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/stic.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We introduce Self-Training on Image Comprehension (STIC), which self-constructs a preference dataset for image descriptions using unlabeled images. Preferred responses are generated through a step-by-step prompt, while dis-preferred responses are generated from either corrupted images or misleading prompts. </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Can Large Language Model Agents Simulate Human Trust Behavior?</h5>
                           <div class="pub-authors" itemprop="author">
                              Chengxing Xie, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, Adel Bibi, Ziniu Hu, David Jurgens, James Evans, Philip Torr, Bernard Ghanem, Guohao Li
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2402.04559">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/camel-ai/agent-trust">CODE</a>
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2024)
                           </div>
                           <div class="col-md-3" style="top:20px">
                              <img src="/img/headers/trust.png" class="pub-banner" itemprop="image" />
                           </div>
                           <div class="col-md-8" style="top:10px">
                              <div class="pub-abstract" itemprop="text">Under the framework of Trust Games, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, indicating the feasibility to simulate human trust behaviors with LLM agents  </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code</h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Ahmet Iscen, Aashi Jain, Thomas Kipf, Yisong Yue, David A. Ross, Cordelia Schmid, Alireza Fathi
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2403.01248">PDF</a>
                           </div>
                           <div class="pub-publication"> International Conference on Machine Learning (ICML 2024, <a href="https://icml.cc/virtual/2024/session/35268">Oral Presentation</a>)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/scene.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We introduces SceneCraft, an LLM Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. SceneCraft can keep self-improving via Library Learning.</div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Symbolic Music Generation with Non-Differentiable Rule Guided Diffusion</h5>
                           <div class="pub-authors" itemprop="author">
                              Yujia Huang, Adishree Ghatare, Yuanzhe Liu, <u><b>Ziniu Hu</b></u>, Qinsheng Zhang, Chandramouli S Sastry, Siddharth Gururani, Sageev Oore, Yisong Yue
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2402.14285">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/yjhuangcd/rule-guided-music">CODE</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://scg-rule-guided-music.github.io/">DEMO</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/yjhuangcd/rule-guided-music?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> International Conference on Machine Learning (ICML 2024, <a href="https://icml.cc/virtual/2024/session/35264">Oral Presentation</a>)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/music_2.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We study the problem of symbolic music generation, with a technical focus on non-differentiable rule guidance by Musical Rules (e.g., note density or chord progression). We propose Stochastic Control Guidance (SCG), a novel guidance method that only requires forward evaluation of rule functions that can work with pre-trained diffusion models in a plug-and-play way, thus achieving training-free guidance for non-differentiable rules for the first time. </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models</h5>
                           <div class="pub-authors" itemprop="author">
                              Xiaoxuan Wang*, <u><b>Ziniu Hu*</b></u>, Pan Lu*, Yanqiao Zhu*, Jieyu Zhang, Satyen Subramaniam, Arjun R Loomba, Shichang Zhang, Yizhou Sun, Wei Wang
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2307.10635.pdf">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/mandyyyyii/scibench">CODE & Dataset</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/mandyyyyii/scibench?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> International Conference on Machine Learning (ICML 2024)
                           </div>
                           <div class="pub-publication"> Covered by <a href="https://www.nature.com/articles/d41586-023-03507-3"> Nature News Feature (15 November 2023) </a>
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/math.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose SciBench to systematically examine LLM's reasoning for complex scientific problem solving. SCIBENCH contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set comprising problems from undergraduate-level exams in computer science and mathematics.     </div>
                        </div>
                     </div>
                  </div>
<!--                   <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Self-Control of LLM Behaviors by Compressing Suffix Gradient into Prefix Controller </h5>
                           <div class="pub-authors" itemprop="author">Min Cai, Yuchen Zhang, Shichang Zhang, Fan Yin, Difan Zou, Yisong Yue, <u><b>Ziniu Hu</b></u>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2406.02721">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/HenryCai11/LLM-Self-Control">CODE</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://colab.research.google.com/drive/1PqROFczbIKoljYlaF9tUEGSIgTXIn1fY?usp=sharing">DEMO</a>
                           </div>
                           <div class="pub-publication"> ICML 2024, Workshop on Mechanistic Interpretability
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/suffix.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose Self-Control, a novel method utilizing suffix gradients to control the behavior of large language models (LLMs) without explicit human annotations, across multiple domains, including emotional modulation, ensuring harmlessness, and enhancing complex reasoning. </div>
                        </div>
                     </div>
                  </div> -->
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">AVIS: Autonomous Visual Information Seeking with Large Language Model Agent </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, Alireza Fathi
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2306.08129">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html">Google AI Blog-Post</a>
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2023)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/control.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">we propose an autonomous information seeking visual question answering framework, AVIS.
                              Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. 
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Learning to Group Auxiliary Datasets for Molecule</h5>
                           <div class="pub-authors" itemprop="author">
                              Tinglin Huang, <u><b>Ziniu Hu</b></u>, Rex Ying
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2307.04052">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/Graph-and-Geometric-Learning/MolGroup">CODE</a>
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2023)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/mols.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose MolGroup to address the limited data problem in molecule property prediction by leveraging auxiliary datasets to improve performance on target datasets, via a routing mechanism w/ bi-level optimization.              </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Towards a Comprehensive Benchmark for FPGA Targeted High-Level Synthesis</h5>
                           <div class="pub-authors" itemprop="author">
                              Yunsheng Bai, Atefeh Sohrabizadeh, Zongyue Qin, <u><b>Ziniu Hu</b></u>, Yizhou Sun, Jason Cong
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://openreview.net/pdf?id=HvcLKgtbco">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/UCLA-DM/HLSyn">CODE & Dataset</a>
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing Systems (NeurIPS 2023, Dataset Track)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/fpga.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text"> High-level synthesis (HLS) aims to raise the abstraction layer in hardware design, enabling the design of domain-specific accelerators (DSAs) like FPGAs using C/C++ instead of hardware description languages.  To enable machine learning models to predict design quality, we present HLSYN, a comprehensive dataset for training and evaluating design quality prediction models for hardware design. </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">AvalonBench: Evaluating LLMs Playing the Game of Avalon</h5>
                           <div class="pub-authors" itemprop="author">
                              Jonathan Light*, Min Cai*, Sheng Shen, Ziniu Hu
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://browse.arxiv.org/pdf/2310.05036.pdf">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/jonathanmli/Avalon-LLM">Game CODE</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://avalonbench.github.io/">DEMO</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/jonathanmli/Avalon-LLM?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> NeurIPS 2023, Foundation Models for Decision Making (<a href="https://sites.google.com/view/fmdm-neurips23/">FMDM</a>) workshop 
                           </div>
                           <div class="col-md-3" style="top:20px">
                              <img src="/img/headers/avalon.webp" class="pub-banner" itemprop="image" />
                           </div>
                           <div class="col-md-8" style="top:10px">
                              <div class="pub-abstract" itemprop="text">we introduce AvalonBench - a comprehensive game environment tailored for evaluating multi-agent LLM Agents. This benchmark incorporates: (1) a game environment for Avalon, (2) rule-based bots as baseline opponents, and (3) ReAct-style LLM agents with tailored prompts for each role.    </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Ahmet Iscen, Chen Sun, Zirui Wang, Kai-Wei Chang, Yizhou Sun, Cordelia Schmid, David A. Ross and Alireza Fathi
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2212.05221">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html">Google AI Blog-Post</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://reveal-cvpr.github.io/">PROJECT</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/google-research/scenic/tree/main/scenic/projects/knowledge_visual_language">CODE (JAX/Scenic) </a><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/google-research/scenic?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> Conference on Computer Vision and Pattern Recognition (CVPR 2023), selected as <a
                              href="https://cvpr2023.thecvf.com/virtual/2023/awards_detail">Highlight</a>.
                           </div>
                           <div class="col-md-3" style="top:20px">
                              <img src="/img/headers/vqa.png" class="pub-banner" itemprop="image" />
                           </div>
                           <div class="col-md-8" style="top:10px">
                              <div class="pub-abstract" itemprop="text">We propose an end-to-end Retrieval-Augmented Visual Language Model (REVEAL) that learns to encode world knowledge into a large-scale memory, 
                                 and to retrieve from it to answer knowledge-intensive queries. 
                                 The key novelty is that the memory, retriever and generator are all pre-trained end-to-end to use a diverse set of multimodal knowledge sources, bringing significant gains. 
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering</h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Yichong Xu, Wenhao Yu, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Kai-Wei Chang and Yizhou Sun
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2211.08380">PDF</a>
                           </div>
                           <div class="pub-publication"> Conference on Empirical Methods in Natural
                              Language Processing (EMNLP 2022)
                           </div>
                           <div class="pub-publication"> <a href="https://socalnlp.github.io/symp22/index.html"> Best Paper Award at SoCal NLP Symposium 2022 </a>
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/oreo.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose a novel symbolic Knowledge Graph (KG) reasoning layer that could be flexibly plugged into most existing Language Models (LMs) and allow LMs to interact with KG, unifying the retrieval and reasoning in a end-to-end framework. OREO-LM improves RoBERTa and T5 on various QA tasks, and the generated reasoning paths could help interpret the model's decision.</div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Improving Multi-Task Generalization via Regularizing Spurious Correlation</h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Zhe Zhao, Xinyang Yi, Tiansheng Yao, Lichan Hong, Yizhou Sun, Ed H. Chi
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2205.09797.pdf">PDF</a>
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing
                              Systems (NeurIPS 2022, <a
                                 href="https://neurips.cc/virtual/2022/spotlight/65012">Spotlight Presentation</a>)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/multi.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We point out the unique challenges of spurious correlation problem 
                              in multi-task setting that influence generalization. We propose Multi-Task Causal Representation Learning (MT-CRL) framework
                              to learn 1) disentangled neural modules; 2) Task-to-Module Causal Graph; 3) Regularize spurious correlation over learned causal graph.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Zero-shot Transfer Learning within a Heterogeneous Graph via Knowledge Transfer Networks</h5>
                           <div class="pub-authors" itemprop="author">
                              Minji Yoon, John Palowitch, Dustin Zelle, <u><b>Ziniu Hu</b></u>, Russ Salakhutdinov, Bryan Perozzi
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2203.02018">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/minjiyoon/KTN">CODE</a>
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing
                              Systems (NeurIPS 2022)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/zero.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose a zero-shot transfer learning module for heterogeneous graph neural networks that transfers knowledge from label-abundant node types to zero-labeled node types through rich relational information given in a single heterogeneous graph.</div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Fuzzy Logic based Logical Query Answering on
                              Knowledge Graph
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              Xuelu Chen, <u><b>Ziniu Hu</b></u>, Yizhou Sun
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/2108.02390.pdf">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/stasl0217/FuzzQE-code">CODE</a>
                           </div>
                           <div class="pub-publication"> AAAI Conference on Artificial Intelligence (AAAI 2022, Oral Presentation)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/kg.PNG" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose FuzzQE, a fuzzy logic based
                              logical query embedding framework for answering FOL queries over KGs.
                              FuzzQE define logical operators in a principled and learningfree manner, which
                              could be trained with only KG without any complex queries.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Relation-Guided Pre-Training for
                              Open-Domain Question Answering
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Kai-Wei Chang, Yizhou Sun
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://aclanthology.org/2021.findings-emnlp.292.pdf">PDF</a>
                           </div>
                           <div class="pub-publication"> Conference on Empirical Methods in Natural
                              Language Processing (EMNLP-Finding 2021)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/qa.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose RGPT-QA to synthesize QA
                              pairs from relation triplets in WikiData and WikiPedia for pre-training
                              Open-Domain QA Model and improves the QA performance, especially for
                              questions with long-tail relations.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning</h5>
                           <div class="pub-authors" itemprop="author"> Da Yin, Liunian Li,
                              <u><b>Ziniu Hu</b></u>, Nanyun Peng, Kai-Wei Chang
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://aclanthology.org/2021.emnlp-main.162.pdf">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/WadeYin9712/GD-VCR">CODE</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://gd-vcr.github.io/explorer.html">Dataset</a>
                           </div>
                           <div class="pub-publication"> Conference on Empirical Methods in Natural
                              Language Processing (EMNLP 2021, Oral Presentation)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/vcr.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">we construct a Geo-Diverse Visual Commonsense Reasoning dataset (GD-VCR)
                              to test Vision-Language models' ability to understand cultural and geo-location-specific commonsense. We find that 
                              the performance of SOTA VL models for non-Western regions (e.g., East Asia, South Asia, and Africa) is significantly
                              lower than that for Western region.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">GPT-GNN: Generative Pre-Training of
                              Graph Neural Networks 
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, Yizhou Sun
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2006.15437">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/acbull/GPT-GNN">CODE </a>
                              <a class="btn btn-primary btn-outline btn-xs" href="/pdf/gpt.pptx">SLIDES</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/acbull/GPT-GNN?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> Conference on Knowledge Discovery and Data
                              Mining (KDD 2020, Oral, <a href="https://www.paperdigest.org/2023/04/most-influential-kdd-papers-2023-04/">Top-10 Cited Paper in KDD'20</a>)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/gpt-intro.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We introduce a self-supervised graph
                              generation task to pre-train GNN. We factorize the likelihood of graph
                              generation into two components: 1) attribute generation, and 2) edge
                              generation, without lossing mutual dependency. 
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Heterogeneous Graph Transformer </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>, Yuxiao Dong, Kuansan Wang, Yizhou Sun
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/2003.01332">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/acbull/pyHGT">CODE (My PyG Impl.) </a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/acbull/HGT-DGL">CODE (DGL)</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hgt_dblp.py">CODE (PyG Re-Impl.)</a>
                              <a class="btn btn-primary btn-outline btn-xs" href="/pdf/hgt.pptx">SLIDES</a>
                              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/acbull/pyhgt?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> The Web Conference (WWW 2020, <a href="https://scholar.google.com/citations?hl=en&vq=eng_databasesinformationsystems&view_op=list_hcore&venue=VtCeQ7ShDloJ.2023">Most Cited Paper in WWW'20</a>)</div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/attention.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We present the Heterogeneous Graph
                              Transformer (HGT) architecture for modeling Web-scale heterogeneous (nodes
                              and edges have multiple types) and dynamic graphs. HGT could automatically
                              learns important meta-paths for different downstream tasks.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Improving Neural Language Generation
                              with Spectrum Control 
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              Lingxiao Wang, Jing Huang, Kevin Huang, <u><b>Ziniu Hu</b></u>, Guangtao
                              Wang, Quanquan Gu
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://openreview.net/pdf?id=ByxY8CNtvr">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://iclr.cc/virtual_2020/poster_ByxY8CNtvr.html">SLIDES</a>
                           </div>
                           <div class="pub-publication"> The International Conference on Learning
                              Representations (ICLR 2020) 
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/nlg.PNG" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose a novel spectrum control
                              approach to address this degeneration problem. The core idea of our method
                              is to directly guide the spectra training of the output embedding matrix
                              with a slow-decaying singular value prior distribution through a
                              reparameterization framework.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Layer-Dependent Importance Sampling
                              for Training Deep and Large Graph Convolutional Networks 
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              Difan Zou*,
                              <u><b>Ziniu Hu</b></u>*, Yewen Wang, Song Jiang, Yizhou Sun, Quanquan Gu
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/pdf/1911.07323.pdf">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/acbull/LADIES">CODE </a><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/acbull/ladies?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication"> Conference on Neural Information Processing
                              Systems (NeurIPS 2019)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/ladies.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose LAyer-Dependent ImportancE
                              Sampling (LADIES). Based on the sampled nodes in the upper layer, LADIES
                              selects their neighborhood nodes, compute the importance probability
                              accordingly and samples a fixed number of nodes within them.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Few-Shot Representation Learning for
                              Out-Of-Vocabulary Words
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>
                              , Ting Chen, Kai-Wei Chang, Yizhou Sun
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/1907.00505">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/acbull/HiCE">CODE </a><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/acbull/hice?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication">Conference of the Association for Computational
                              Linguistics (ACL 2019)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/oov.png" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We formulate the learning of OOV
                              embedding as a few-shot regression problem by predicting an oracle embedding
                              vector (defined as embedding trained with abundant observations) based on
                              only K contexts. Specifically, we use Model-Agnostic Meta-Learning (MAML)
                              for adapting a hierachical Transformer to the new corpus fast and robustly.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Unbiased LambdaMART: An Unbiased
                              Pairwise Learning-to-Rank Algorithm
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>
                              , Yang Wang, Qu Peng, Hang Li
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/1809.05818">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/acbull/Unbiased_LambdaMart">CODE </a><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/acbull/unbiased_lambdamart?logo=github&style=flat-square">
                           </div>
                           <div class="pub-publication">The Web Conference (WWW 2019)</div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/unbias.jpg" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We propose a novel framework for
                              pairwise learning-to-rank. Our algorithm, Unbiased LambdaMART can jointly
                              estimate the biases at click positions and the biases at unclick positions,
                              and learn an unbiased ranker.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Emoji-Powered Representation Learning
                              for Cross-Lingual Sentiment Classification
                           </h5>
                           <div class="pub-authors" itemprop="author">Zhenpeng Chen*, Sheng Shen*,
                              <u><b>Ziniu Hu</b></u>
                              , Xuan Lu, Qiaozhu Mei, Xuanzhe Liu
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/1806.02557">PDF</a>
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://github.com/sIncerass/ELSA">CODE</a>
                           </div>
                           <div class="pub-publication">The Web Conference (WWW 2019, <a
                              href="https://www2019.thewebconf.org/winners">Best Full Paper Award</a>)
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/emoji.jpg" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We employ emoji prediction task as the
                              instrument to learn both the cross-language and language-specific sentiment
                              patterns in different languages.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                     <div class="row">
                        <div class="col-md-12">
                           <h5 class="article-title" itemprop="name">Listening to Chaotic Whispers: A Deep
                              Learning Framework for News-oriented Stock Trend Prediction
                           </h5>
                           <div class="pub-authors" itemprop="author">
                              <u><b>Ziniu Hu</b></u>
                              , Weiqing Liu, Jiang Bian, Xuanzhe Liu, Tie-Yan Liu
                              <a class="btn btn-primary btn-outline btn-xs"
                                 href="https://arxiv.org/abs/1712.02136">PDF</a>
                           </div>
                           <div class="pub-publication">Conference on Web Search and Data Mining (WSDM
                              2018).
                           </div>
                        </div>
                        <div class="col-md-3" style="top:20px">
                           <img src="/img/headers/profit.PNG" class="pub-banner" itemprop="image" />
                        </div>
                        <div class="col-md-8" style="top:10px">
                           <div class="pub-abstract" itemprop="text">We designed a Hybrid Attention
                              Networkss(HAN) to predict the stock trend based on the sequence of recent
                              related news, with self-paced learning mechanism to guide efficient
                              learning.
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
            </div>
         </div>
         </div>
      </section>
      <section id="service" class="home-section">
         <div class="container">
            <div class="row">
               <div class="col-md-12">
                  <div class="col-sm-12">
                     <h3>Teaching Experience</h3>
                     <ul class="ul-interests">
                        <li> Lecturer for UCLA CS 145: Introduction to Data Mining, 2024 Spring.</li>
                        <li> <a href="https://github.com/yichousun/Winter2021_CS249_GNN/">Teaching Assistant for UCLA CS 249: Graph Neural Networks, 2021 Winter.</a> </li>
                        <li> <a href="https://catalog.registrar.ucla.edu/course/2022/COMSCIM146"> Teaching Assistant for UCLA CS 146: Introduction to Machine Learning, 2019 Fall.</a> </li>
                     </ul>
                  </div>
               </div>
               <div class="col-md-12">
                  <div class="col-sm-12">
                     <h3>Academic Services</h3>
                     <ul class="ul-interests">
                        <li> <b>Area Chair</b> of <b>WWW</b> 2024,2025, <b>NeurIPS</b> 2025, <b>ICLR</b> 2025, <b>ACL</b> 2025</li>
                        <li> <b>Journal Associate Editor</b> of Transaction on Big Data (TBD)</li>
                        <li> <a href="https://kdd.org/kdd2023/organizers/"><b>Research Track Workflow Co-Chair: SIGKDD 2023 (ACM Conference on Knowledge Discovery and Data Mining) </b></a> </li>
                        <li> <b>Program Committee / Reviewer</b>: Neurips (<a href="https://neurips.cc/Conferences/2022/ProgramCommittee">Top Reviewer Award @ 2022</a>), ICML, ICLR, KDD, ACL (+Rolling Review), EMNLP, AAAI, IJCAI, WWW, CIKM (Annual reviewer since 2019, reviewed for 100+ conference papers)</li>
                        <li> <b>Journal Reviewer</b>: TKDE, TKDD, TOIS, TPAMI, TCS, TBD, JAIR (Reviewed for 20+ Journal papers) </li>
                        <li> <b>Program Committee Co-Chair</b>: <a href="https://www.aminer.cn/ssl_www2021">SSL @ WWW 2021 (Workshop on Self-Supervised Learning for the Web)</a> </li>
                        <li> <b>Senior PC & Meta-Reviewer</b>: <a href="https://knowledge-nlp.github.io/aaai2023/">KnowledgeNLP @ AAAI 2023 (Workshop on Knowledge Augmented Methods for NLP) </a> </li>
                        <li> <a href="https://ucla-dm.github.io/DM_website/reading/course.html"><b>Reading Group Organizer @ UCLA-DM Lab</b></a> from 2018 to 2022. </li>
                     </ul>
                  </div>
               </div>
               <div class="col-md-12">
                  <div class="col-sm-12">
                     <h3>Invited Talks</h3>
                     <ul class="ul-interests">
                        <li>
                           Enhancing LLM Reasoning via Reinforcement Learning and Tree Search
                           <ul>
                              <li>
                                 <a href="https://bigmodel.ai/aigc-kdd24/">Keynote at KDD 2024 Generative AI Day</a>
                              </li>
                              <li>
                                 <a href="https://bigmodel.ai/aigc-kdd24/">Contributed Talk at INFORMS APS 2025</a>
                              </li>
                           </ul>
                        </li>
                        <li>
                           Make Knowledge Computable: Differentiable Neural-Symbolic Reasoning
                           <ul>
                              <li>
                                 USC AI Seminars at USC Information Sciences Institute
                              </li>
                              <li>
                                 ByteDance AI Lab, AI Seminar
                              </li>
                           </ul>
                        </li>
                        <li>
                           Self-Supervised Learning and Logical Reasoning over Knowledge Graphs
                           <ul>
                              <li>
                                 DataFunTalk, Graph Learning Seminar 
                              </li>
                              <li>
                                 <a href="https://www.bilibili.com/video/BV1UQ4y167Uc">AI Time, Tsinghua University</a>
                              </li>
                           </ul>
                        </li>
                     </ul>
                  </div>
               </div>
            </div>
         </div>
      </section>
      <div style="width: 33%; text-align: center; margin: 0 auto;">
         <script type="text/javascript" id="clustrmaps"
            src="//cdn.clustrmaps.com/map_v2.js?d=tebCSlmqux9N9QrcNmOiT0PXzoscPYQd7ftMh0JTTv0&amp;cl=ffffff&amp;w=a"></script>
      </div>
      <br />
      <footer class="site-footer">
         <div class="container">
            <p class="powered-by">&copy; 2019 Ziniu Hu &middot; Powered by the
               <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for
               <a href="http://gohugo.io" target="_blank">Hugo</a>.
               <span class="pull-right" aria-hidden="true">
               <a href="#" id="back_to_top">
               <span class="button_icon">
               <i class="fa fa-chevron-up fa-2x"></i></span>
               </a>
               </span>
            </p>
         </div>
      </footer>
      <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
      <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
      <script src="/js/jquery-1.12.3.min.js"></script>
      <script src="/js/bootstrap.min.js"></script>
      <script src="/js/isotope.pkgd.min.js"></script>
      <script src="//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.1/imagesloaded.pkgd.min.js"></script>
      <script src="/js/hugo-academic.js"></script>
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script>
   </body>
</html>
